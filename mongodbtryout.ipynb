{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e7f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\genaichnsirusr21\\aiforceone\\.venv\\lib\\site-packages (4.15.5)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\genaichnsirusr21\\aiforceone\\.venv\\lib\\site-packages (from pymongo) (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8277e74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to MongoDB at mongodb://localhost:27017/\n",
      "‚û°Ô∏è Targeting database: MyLocalDB, collection: Products\n",
      "‚ùå JSON ERROR: Failed to decode JSON from file. Check file syntax. Error: Extra data: line 2 column 1 (char 711)\n",
      "‚û°Ô∏è MongoDB connection closed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import PyMongoError, BulkWriteError\n",
    "\n",
    "# --- Configuration ---\n",
    "MONGODB_URI = \"mongodb://localhost:27017/\"  # Default local MongoDB URI\n",
    "DATABASE_NAME = \"MyLocalDB\"                # Your database name\n",
    "COLLECTION_NAME = \"Products\"               # Your collection name\n",
    "JSON_FILE_PATH = \"openlineage.json\"               # The name of your JSON file\n",
    "# --- End Configuration ---\n",
    "\n",
    "def import_json_to_mongodb(uri, db_name, collection_name, file_path):\n",
    "    \"\"\"\n",
    "    Connects to MongoDB, reads a JSON file, and inserts the data.\n",
    "    \"\"\"\n",
    "    client = None\n",
    "    try:\n",
    "        # 1. Connect to MongoDB\n",
    "        client = MongoClient(uri)\n",
    "        # The ismaster command is cheap and does not require auth.\n",
    "        client.admin.command('ping') \n",
    "        print(f\"‚úÖ Successfully connected to MongoDB at {uri}\")\n",
    "\n",
    "        # 2. Get Database and Collection\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "        print(f\"‚û°Ô∏è Targeting database: {db_name}, collection: {collection_name}\")\n",
    "\n",
    "        # 3. Load JSON data from file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file_data = json.load(file)\n",
    "            print(f\"‚úÖ Successfully loaded data from {file_path}\")\n",
    "\n",
    "        # 4. Insert data based on its structure\n",
    "        if isinstance(file_data, list):\n",
    "            # If the JSON file is a list of documents, use insert_many()\n",
    "            result = collection.insert_many(file_data)\n",
    "            print(f\"‚ú® Inserted {len(result.inserted_ids)} documents using insert_many().\")\n",
    "            print(\"--- First 3 IDs: \", result.inserted_ids[:3])\n",
    "        elif isinstance(file_data, dict):\n",
    "            # If the JSON file is a single document (dictionary), use insert_one()\n",
    "            result = collection.insert_one(file_data)\n",
    "            print(f\"‚ú® Inserted 1 document using insert_one(). ID: {result.inserted_id}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error: JSON file content is neither a list nor a dictionary. Type: {type(file_data)}\")\n",
    "            return\n",
    "\n",
    "    except ConnectionError:\n",
    "        print(f\"‚ùå CONNECTION ERROR: Could not connect to MongoDB. Ensure your MongoDB server is running at {uri}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå FILE ERROR: The file '{file_path}' was not found.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON ERROR: Failed to decode JSON from file. Check file syntax. Error: {e}\")\n",
    "    except BulkWriteError as e:\n",
    "        # Catches errors like duplicate keys if you are inserting documents with specific _id fields\n",
    "        print(f\"‚ö†Ô∏è BULK WRITE ERROR: Some documents failed to insert. {e.details}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # 5. Close the connection\n",
    "        if client:\n",
    "            client.close()\n",
    "            print(\"‚û°Ô∏è MongoDB connection closed.\")\n",
    "\n",
    "# Run the function\n",
    "import_json_to_mongodb(MONGODB_URI, DATABASE_NAME, COLLECTION_NAME, JSON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d04e284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to MongoDB at mongodb://localhost:27017/\n",
      "‚û°Ô∏è Targeting database: OpenLineageDB, collection: lineage_events\n",
      "‚úÖ Successfully loaded 2 documents from openlineage.json\n",
      "‚ú® Inserted 2 documents using insert_many().\n",
      "--- First 3 IDs:  [ObjectId('6932432ba25a45a9129830fc'), ObjectId('6932432ba25a45a9129830fd')]\n",
      "‚û°Ô∏è MongoDB connection closed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import PyMongoError, BulkWriteError\n",
    "\n",
    "# --- Configuration ---\n",
    "MONGODB_URI = \"mongodb://localhost:27017/\" \n",
    "DATABASE_NAME = \"OpenLineageDB\"               # Changed for clarity\n",
    "COLLECTION_NAME = \"lineage_events\"           # Changed for clarity\n",
    "JSON_FILE_PATH = \"openlineage.json\"          # Confirmed file name\n",
    "# --- End Configuration ---\n",
    "\n",
    "def import_jsonl_to_mongodb(uri, db_name, collection_name, file_path):\n",
    "    \"\"\"\n",
    "    Connects to MongoDB, reads a JSONL file line by line, and inserts the data.\n",
    "    \"\"\"\n",
    "    client = None\n",
    "    documents = [] # List to hold all parsed documents\n",
    "\n",
    "    try:\n",
    "        # 1. Connect to MongoDB\n",
    "        client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "        client.admin.command('ping') \n",
    "        print(f\"‚úÖ Successfully connected to MongoDB at {uri}\")\n",
    "\n",
    "        # 2. Get Database and Collection\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "        print(f\"‚û°Ô∏è Targeting database: {db_name}, collection: {collection_name}\")\n",
    "\n",
    "        # 3. Load JSON data line by line (Crucial change for JSONL format)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line_number, line in enumerate(file, 1):\n",
    "                # Skip empty lines\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                try:\n",
    "                    # Use json.loads() for a string line, not json.load() for the whole file\n",
    "                    documents.append(json.loads(line))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ùå JSONL PARSE ERROR on line {line_number}: {e}\")\n",
    "                    # You might choose to break here or continue to the next line\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(documents)} documents from {file_path}\")\n",
    "\n",
    "        # 4. Insert data using insert_many()\n",
    "        if documents:\n",
    "            result = collection.insert_many(documents)\n",
    "            print(f\"‚ú® Inserted {len(result.inserted_ids)} documents using insert_many().\")\n",
    "            print(\"--- First 3 IDs: \", result.inserted_ids[:3])\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è File was empty or contained no valid documents. No documents inserted.\")\n",
    "\n",
    "    except PyMongoError as e: \n",
    "        print(f\"‚ùå MONGODB ERROR: Connection failed. Ensure your MongoDB server is running at {uri}.\")\n",
    "        print(f\"Details: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå FILE ERROR: The file '{file_path}' was not found. Check the path.\")\n",
    "    except BulkWriteError as e:\n",
    "        print(f\"‚ö†Ô∏è BULK WRITE ERROR: Some documents failed to insert. {e.details}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # 5. Close the connection\n",
    "        if client:\n",
    "            client.close()\n",
    "            print(\"‚û°Ô∏è MongoDB connection closed.\")\n",
    "\n",
    "# Run the function\n",
    "import_jsonl_to_mongodb(MONGODB_URI, DATABASE_NAME, COLLECTION_NAME, JSON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd4246",
   "metadata": {},
   "source": [
    "# Working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bfb2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient, ASCENDING, WriteConcern\n",
    "from pymongo.errors import CollectionInvalid\n",
    "# from pymongo import MongoClient\n",
    "from pymongo.errors import PyMongoError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555e7ae",
   "metadata": {},
   "source": [
    "# Upload into Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3b719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pymongo import MongoClient\n",
    "# from pymongo.errors import PyMongoError\n",
    "\n",
    "# # --- Configuration (MUST MATCH your import script) ---\n",
    "# MONGODB_URI = \"mongodb://localhost:27017/\"\n",
    "# DATABASE_NAME = \"OpenLineageDB\"               # Must match DATABASE_NAME in import_mongo.txt [cite: 1]\n",
    "# COLLECTION_NAME = \"lineage_events\"           # Must match COLLECTION_NAME in import_mongo.txt [cite: 1]\n",
    "# # --- End Configuration ---\n",
    "\n",
    "# def retrieve_data_from_mongodb(uri, db_name, collection_name):\n",
    "#     \"\"\"\n",
    "#     Connects to MongoDB and retrieves all documents from the specified collection.\n",
    "#     \"\"\"\n",
    "#     client = None\n",
    "#     try:\n",
    "#         # 1. Connect to MongoDB\n",
    "#         client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "#         client.admin.command('ping') \n",
    "#         print(f\"‚úÖ Successfully connected to MongoDB at {uri}\")\n",
    "\n",
    "#         # 2. Get Database and Collection\n",
    "#         db = client[db_name]\n",
    "#         collection = db[collection_name] # Using the collection from your import script [cite: 3]\n",
    "#         print(f\"‚û°Ô∏è Targeting database: {db_name}, collection: {collection_name}\")\n",
    "        \n",
    "#         # 3. Define the Query (find all documents)\n",
    "#         # An empty dictionary {} finds all documents in the collection\n",
    "#         query_filter = {} \n",
    "        \n",
    "#         # 4. Execute the Query and Retrieve Documents\n",
    "#         cursor = collection.find(query_filter)\n",
    "        \n",
    "#         print(\"\\nüìä Retrieved Documents:\")\n",
    "#         count = 0\n",
    "        \n",
    "#         # 5. Iterate and Print Results\n",
    "#         for document in cursor:\n",
    "#             # MongoDB's _id field is a BSON ObjectId, which needs to be converted\n",
    "#             # to a string for clean JSON printing if you use json.dumps()\n",
    "#             document['_id'] = str(document['_id'])\n",
    "            \n",
    "#             # Use json.dumps for clean, formatted output\n",
    "#             print(json.dumps(document, indent=2))\n",
    "#             count += 1\n",
    "            \n",
    "#             # Optional: Limit the output for large collections\n",
    "#             if count >= 10:\n",
    "#                 print(f\"...\\n(Stopping output after {count} documents for brevity.)\")\n",
    "#                 break\n",
    "        \n",
    "#         if count == 0:\n",
    "#             print(\"‚ö†Ô∏è No documents found in the collection.\")\n",
    "\n",
    "#     except PyMongoError as e: \n",
    "#         # Handles connection issues (similar to your import code )\n",
    "#         print(f\"‚ùå MONGODB ERROR: Connection failed. Ensure your MongoDB server is running at {uri}.\")\n",
    "#         print(f\"Details: {e}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå An unexpected error occurred: {e}\") # Catches other errors [cite: 8]\n",
    "#     finally:\n",
    "#         # 6. Close the connection\n",
    "#         if client:\n",
    "#             client.close()\n",
    "#             print(\"‚û°Ô∏è MongoDB connection closed.\")\n",
    "\n",
    "# # Run the function\n",
    "# retrieve_data_from_mongodb(MONGODB_URI, DATABASE_NAME, COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86558abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient, ASCENDING, WriteConcern\n",
    "from pymongo.errors import CollectionInvalid\n",
    "import json\n",
    "from pymongo import MongoClient, ASCENDING, WriteConcern\n",
    "from pymongo.errors import CollectionInvalid\n",
    "# from pymongo import MongoClient\n",
    "from pymongo.errors import PyMongoError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "201b1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MONGODB_URI = \"mongodb://localhost:27017/\" \n",
    "DATABASE_NAME = \"Pyspark_OpenLineageDB\"               # Changed for clarity\n",
    "COLLECTION_NAME = \"lineage_events\"           # Changed for clarity\n",
    "JSON_FILE_PATH = \"pyspark_lineage.json\"          # Confirmed file name\n",
    "# --- End Configuration ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8926d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to MongoDB database 'Pyspark_OpenLineageDB'.\n",
      "Attempting to insert 6 documents into 'lineage_events'...\n",
      "‚úÖ Successfully inserted 6 documents.\n",
      "Collection: Pyspark_OpenLineageDB.lineage_events\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "def upload_json_to_mongodb(file_path, mongo_uri, db_name, collection_name):\n",
    "    \"\"\"\n",
    "    Connects to MongoDB, reads a file containing line-delimited JSON objects, \n",
    "    and inserts each object as a separate document into a specified collection.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Connect to MongoDB\n",
    "        client = MongoClient(mongo_uri)\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "        print(f\"‚úÖ Successfully connected to MongoDB database '{db_name}'.\")\n",
    "\n",
    "        documents_to_insert = []\n",
    "        \n",
    "        # 2. Read the file line by line\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line_number, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue  # Skip empty lines\n",
    "\n",
    "                try:\n",
    "                    # 3. Parse the line into a Python dictionary (JSON object)\n",
    "                    document = json.loads(line)\n",
    "                    documents_to_insert.append(document)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ö†Ô∏è Warning: Could not parse line {line_number + 1} as JSON. Skipping. Error: {e}\")\n",
    "        \n",
    "        if not documents_to_insert:\n",
    "            print(f\"‚ùå No valid JSON documents found in '{file_path}'. Exiting.\")\n",
    "            return\n",
    "\n",
    "        # 4. Insert all documents into the collection\n",
    "        print(f\"Attempting to insert {len(documents_to_insert)} documents into '{collection_name}'...\")\n",
    "        \n",
    "        # Use insert_many for efficiency\n",
    "        result = collection.insert_many(documents_to_insert)\n",
    "        \n",
    "        print(f\"‚úÖ Successfully inserted {len(result.inserted_ids)} documents.\")\n",
    "        print(f\"Collection: {db_name}.{collection_name}\")\n",
    "        \n",
    "        # Optional: Print the IDs of the inserted documents\n",
    "        # print(\"Inserted IDs:\", result.inserted_ids)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: The file '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred during the MongoDB operation: {e}\")\n",
    "    finally:\n",
    "        # 5. Close the MongoDB connection\n",
    "        if 'client' in locals() and client:\n",
    "            client.close()\n",
    "            print(\"Connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have 'pymongo' installed: pip install pymongo\n",
    "    upload_json_to_mongodb(JSON_FILE_PATH, MONGODB_URI, DATABASE_NAME, COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9ccc5",
   "metadata": {},
   "source": [
    "## trail 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "746ee85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_unique_index(collection):\n",
    "#     \"\"\"Ensures a unique index exists on (run.runId, eventType) to prevent duplicates.\"\"\"\n",
    "#     try:\n",
    "#         index_name = \"run_event_unique_index\"\n",
    "#         collection.create_index(\n",
    "#             [(\"run.runId\", ASCENDING), (\"eventType\", ASCENDING)],\n",
    "#             unique=True,\n",
    "#             name=index_name\n",
    "#         )\n",
    "#         print(f\"‚úÖ Ensured unique index '{index_name}' on (run.runId, eventType).\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error creating index: {e}\")\n",
    "        \n",
    "# def upload_json_to_mongodb_safe(file_path, mongo_uri, db_name, collection_name):\n",
    "#     \"\"\"\n",
    "#     Connects to MongoDB, reads line-delimited JSON, and uses upserts (update or insert) \n",
    "#     to avoid duplicate entries based on the compound key (runId, eventType).\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # 1. Connect to MongoDB\n",
    "#         # Use WriteConcern for robust write confirmation\n",
    "#         client = MongoClient(mongo_uri)\n",
    "#         db = client.get_database(db_name, write_concern=WriteConcern(w=\"majority\", wtimeout=5000))\n",
    "#         collection = db[collection_name]\n",
    "#         print(f\"‚úÖ Successfully connected to MongoDB database '{db_name}'.\")\n",
    "\n",
    "#         # 2. Create Unique Index\n",
    "#         create_unique_index(collection)\n",
    "\n",
    "#         inserted_count = 0\n",
    "#         skipped_count = 0\n",
    "        \n",
    "#         # 3. Read the file line by line and perform upserts\n",
    "#         with open(file_path, 'r') as f:\n",
    "#             for line_number, line in enumerate(f):\n",
    "#                 line = line.strip()\n",
    "#                 if not line:\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     document = json.loads(line)\n",
    "                    \n",
    "#                     # Define the unique filter using the job's Run ID and Event Type\n",
    "#                     filter_query = {\n",
    "#                         \"run.runId\": document[\"run\"][\"runId\"],\n",
    "#                         \"eventType\": document[\"eventType\"]\n",
    "#                     }\n",
    "                    \n",
    "#                     # Use $set to update the document, which acts as the insertion content on upsert\n",
    "#                     update_operation = {\"$set\": document}\n",
    "                    \n",
    "#                     # Perform the upsert: update if found, insert if not found\n",
    "#                     result = collection.update_one(\n",
    "#                         filter_query,\n",
    "#                         update_operation,\n",
    "#                         upsert=True\n",
    "#                     )\n",
    "                    \n",
    "#                     # Track counts\n",
    "#                     if result.upserted_id:\n",
    "#                         inserted_count += 1\n",
    "#                     elif result.matched_count == 1 and result.modified_count == 0:\n",
    "#                          skipped_count += 1 \n",
    "\n",
    "#                 except json.JSONDecodeError as e:\n",
    "#                     print(f\"‚ö†Ô∏è Warning: Could not parse line {line_number + 1} as JSON. Skipping. Error: {e}\")\n",
    "                \n",
    "#         print(\"-\" * 50)\n",
    "#         print(f\"Upload Summary for '{file_path}':\")\n",
    "#         print(f\"‚úÖ Newly Inserted Documents (Upserts): {inserted_count}\")\n",
    "#         print(f\"‚è≠Ô∏è Skipped (Existing and Unchanged): {skipped_count}\")\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"‚ùå Error: The file '{file_path}' was not found.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå An error occurred during the MongoDB operation: {e}\")\n",
    "#     finally:\n",
    "#         # 4. Close the MongoDB connection\n",
    "#         if 'client' in locals() and client:\n",
    "#             client.close()\n",
    "#             print(\"Connection closed.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Ensure you have 'pymongo' installed: pip install pymongo\n",
    "#     upload_json_to_mongodb_safe(JSON_FILE_PATH, MONGODB_URI, DATABASE_NAME, COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_and_print_json(mongo_uri, db_name, collection_name):\n",
    "#     \"\"\"\n",
    "#     Connects to MongoDB, retrieves all documents from a collection, \n",
    "#     excludes the '_id' field, and prints the result as a list of JSON objects.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # 1. Connect to MongoDB\n",
    "#         client = MongoClient(mongo_uri)\n",
    "#         db = client[db_name]\n",
    "#         collection = db[collection_name]\n",
    "#         print(f\"‚úÖ Successfully connected to MongoDB database '{db_name}'.\")\n",
    "\n",
    "#         # 2. Retrieve all documents\n",
    "#         # The projection {'_id': 0} excludes the MongoDB-added ObjectId field\n",
    "#         cursor = collection.find({}, {'_id': 0})\n",
    "        \n",
    "#         retrieved_documents = list(cursor)\n",
    "\n",
    "#         if not retrieved_documents:\n",
    "#             print(f\"‚ùå No documents found in collection '{collection_name}'.\")\n",
    "#             return\n",
    "\n",
    "#         print(f\"‚úÖ Retrieved {len(retrieved_documents)} documents. Printing documents:\")\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "#         # 3. Print each document as a formatted JSON string\n",
    "#         for doc in retrieved_documents:\n",
    "#             # The 'doc' is already a standard Python dictionary, \n",
    "#             # which is the direct equivalent of the original JSON object.\n",
    "            \n",
    "#             # Using json.dumps to print it as a single-line JSON string \n",
    "#             # to match the original file format (optional, you could use pprint for readability)\n",
    "#             json_output = json.dumps(doc)\n",
    "#             print(json_output)\n",
    "            \n",
    "#         print(\"-\" * 50)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå An error occurred during the MongoDB retrieval operation: {e}\")\n",
    "#     finally:\n",
    "#         # 4. Close the MongoDB connection\n",
    "#         if 'client' in locals() and client:\n",
    "#             client.close()\n",
    "#             print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d0b676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## chatgpt created this\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "def retrieve_and_print_json(mongo_uri, db_name, collection_name):\n",
    "    \"\"\"\n",
    "    Connects to MongoDB, retrieves only documents where eventType = COMPLETE,\n",
    "    sorts by eventTime in descending order, excludes _id, and prints results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_uri)\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "        print(collection)\n",
    "        print(f\"‚úÖ Connected to MongoDB database '{db_name}'\")\n",
    "\n",
    "        # Query:\n",
    "        # 1. Filter eventType = COMPLETE\n",
    "        # 2. Sort by eventTime descending (-1)\n",
    "        cursor = collection.find(\n",
    "            {\"eventType\": \"COMPLETE\"},\n",
    "            {\"_id\": 0}\n",
    "        ).sort(\"eventTime\", -1)\n",
    "\n",
    "        completed_events = list(cursor)\n",
    "\n",
    "        if not completed_events:\n",
    "            print(\"‚ùå No COMPLETE events found.\")\n",
    "            return\n",
    "\n",
    "        print(f\"‚úÖ Retrieved {len(completed_events)} COMPLETE events (sorted by latest eventTime)\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # Print each JSON\n",
    "        for doc in completed_events:\n",
    "            print(json.dumps(doc))\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå MongoDB Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        if 'client' in locals() and client:\n",
    "            client.close()\n",
    "            print(\"üîå Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ed5439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "def retrieve_and_print_json_getlatest(mongo_uri, db_name, collection_name):\n",
    "    \"\"\"\n",
    "    Connects to MongoDB, retrieves only documents where eventType = COMPLETE,\n",
    "    gets the latest entry for each unique job.name based on eventTime,\n",
    "    and prints results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_uri)\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "        print(collection)\n",
    "        print(f\"‚úÖ Connected to MongoDB database '{db_name}'\")\n",
    "\n",
    "        # Aggregation pipeline:\n",
    "        # 1. Filter eventType = COMPLETE\n",
    "        # 2. Sort by eventTime descending (to get latest first)\n",
    "        # 3. Group by job.name and take the first (latest) document\n",
    "        # 4. Replace root to return the original document structure\n",
    "        pipeline = [\n",
    "            # Filter only COMPLETE events\n",
    "            {\"$match\": {\"eventType\": \"COMPLETE\"}},\n",
    "            \n",
    "            # Sort by eventTime descending (latest first)\n",
    "            {\"$sort\": {\"eventTime\": -1}},\n",
    "            \n",
    "            # Group by job.name and take the first document (which is the latest)\n",
    "            {\"$group\": {\n",
    "                \"_id\": \"$job.name\",\n",
    "                \"latestEvent\": {\"$first\": \"$$ROOT\"}\n",
    "            }},\n",
    "            \n",
    "            # Replace root to get back the original document structure\n",
    "            {\"$replaceRoot\": {\"newRoot\": \"$latestEvent\"}},\n",
    "            \n",
    "            # Remove MongoDB's _id field\n",
    "            {\"$project\": {\"_id\": 0}},\n",
    "            \n",
    "            # Optional: Sort by eventTime again for final output\n",
    "            {\"$sort\": {\"eventTime\": -1}}\n",
    "        ]\n",
    "\n",
    "        completed_events = list(collection.aggregate(pipeline))\n",
    "\n",
    "        if not completed_events:\n",
    "            print(\"‚ùå No COMPLETE events found.\")\n",
    "            return\n",
    "\n",
    "        print(f\"‚úÖ Retrieved {len(completed_events)} unique jobs with latest COMPLETE events\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # Print each JSON\n",
    "        for doc in completed_events:\n",
    "            print(json.dumps(doc, default=str))  # default=str handles datetime objects\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå MongoDB Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        if 'client' in locals() and client:\n",
    "            client.close()\n",
    "            print(\"üîå Connection closed.\")\n",
    "    return completed_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f38cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'Pyspark_OpenLineageDB'), 'lineage_events')\n"
     ]
    }
   ],
   "source": [
    "     \n",
    "# --- Configuration ---\n",
    "MONGODB_URI = \"mongodb://localhost:27017/\" \n",
    "DATABASE_NAME = \"Pyspark_OpenLineageDB\"               # Changed for clarity\n",
    "COLLECTION_NAME = \"lineage_events\"           # Changed for clarity\n",
    "JSON_FILE_PATH = \"pyspark_lineage.json\"          # Confirmed file name\n",
    "# --- End Configuration ---\n",
    "# client = MongoClient(MONGODB_URI)\n",
    "# db = client[DATABASE_NAME]\n",
    "# collection = db[COLLECTION_NAME]\n",
    "# print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cbbf3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'Pyspark_OpenLineageDB'), 'lineage_events')\n",
      "‚úÖ Connected to MongoDB database 'Pyspark_OpenLineageDB'\n",
      "‚úÖ Retrieved 2 unique jobs with latest COMPLETE events\n",
      "------------------------------------------------------------\n",
      "{\"eventTime\": \"2025-12-05T04:51:07.469Z\", \"producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"schemaURL\": \"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent\", \"eventType\": \"COMPLETE\", \"run\": {\"runId\": \"019aecd9-65c4-77c5-ab1b-584ff2b7a5dd\", \"facets\": {\"spark_properties\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\", \"properties\": {\"spark.master\": \"local[*]\", \"spark.app.name\": \"PySparkLineage\"}}, \"processing_engine\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet\", \"version\": \"3.5.7\", \"name\": \"spark\", \"openlineageAdapterVersion\": \"1.40.1\"}, \"environment-properties\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\", \"environment-properties\": {}}}}, \"job\": {\"namespace\": \"default\", \"name\": \"py_spark_lineage\", \"facets\": {\"jobType\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/2-0-3/JobTypeJobFacet.json#/$defs/JobTypeJobFacet\", \"processingType\": \"NONE\", \"integration\": \"SPARK\", \"jobType\": \"APPLICATION\"}}}, \"inputs\": [], \"outputs\": []}\n",
      "{\"eventTime\": \"2025-12-05T04:51:04.919Z\", \"producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"schemaURL\": \"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent\", \"eventType\": \"COMPLETE\", \"run\": {\"runId\": \"019aecd9-6f06-7e59-b7d1-765db69d6f7b\", \"facets\": {\"parent\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/1-1-0/ParentRunFacet.json#/$defs/ParentRunFacet\", \"run\": {\"runId\": \"019aecd9-65c4-77c5-ab1b-584ff2b7a5dd\"}, \"job\": {\"namespace\": \"default\", \"name\": \"py_spark_lineage\"}, \"root\": {\"run\": {\"runId\": \"019aecd9-65c4-77c5-ab1b-584ff2b7a5dd\"}, \"job\": {\"namespace\": \"default\", \"name\": \"PySparkLineage\"}}}, \"spark_properties\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\", \"properties\": {\"spark.master\": \"local[*]\", \"spark.app.name\": \"PySparkLineage\"}}, \"processing_engine\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet\", \"version\": \"3.5.7\", \"name\": \"spark\", \"openlineageAdapterVersion\": \"1.40.1\"}, \"environment-properties\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\", \"environment-properties\": {}}}}, \"job\": {\"namespace\": \"default\", \"name\": \"py_spark_lineage.collect_limit\", \"facets\": {\"jobType\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/2-0-3/JobTypeJobFacet.json#/$defs/JobTypeJobFacet\", \"processingType\": \"BATCH\", \"integration\": \"SPARK\", \"jobType\": \"SQL_JOB\"}}}, \"inputs\": [{\"namespace\": \"file\", \"name\": \"/C:/Users/GenAICHNSIRUSR22/srinath/output_data.csv\", \"facets\": {\"dataSource\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/1-0-1/DatasourceDatasetFacet.json#/$defs/DatasourceDatasetFacet\", \"name\": \"file\", \"uri\": \"file\"}, \"schema\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/1-2-0/SchemaDatasetFacet.json#/$defs/SchemaDatasetFacet\", \"fields\": [{\"name\": \"value\", \"type\": \"string\"}]}}, \"inputFacets\": {\"inputStatistics\": {\"_producer\": \"https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark\", \"_schemaURL\": \"https://openlineage.io/spec/facets/1-0-0/InputStatisticsInputDatasetFacet.json#/$defs/InputStatisticsInputDatasetFacet\", \"size\": 3342, \"fileCount\": 1}}}], \"outputs\": []}\n",
      "------------------------------------------------------------\n",
      "üîå Connection closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'eventTime': '2025-12-05T04:51:07.469Z',\n",
       "  'producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "  'schemaURL': 'https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent',\n",
       "  'eventType': 'COMPLETE',\n",
       "  'run': {'runId': '019aecd9-65c4-77c5-ab1b-584ff2b7a5dd',\n",
       "   'facets': {'spark_properties': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet',\n",
       "     'properties': {'spark.master': 'local[*]',\n",
       "      'spark.app.name': 'PySparkLineage'}},\n",
       "    'processing_engine': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet',\n",
       "     'version': '3.5.7',\n",
       "     'name': 'spark',\n",
       "     'openlineageAdapterVersion': '1.40.1'},\n",
       "    'environment-properties': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet',\n",
       "     'environment-properties': {}}}},\n",
       "  'job': {'namespace': 'default',\n",
       "   'name': 'py_spark_lineage',\n",
       "   'facets': {'jobType': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/facets/2-0-3/JobTypeJobFacet.json#/$defs/JobTypeJobFacet',\n",
       "     'processingType': 'NONE',\n",
       "     'integration': 'SPARK',\n",
       "     'jobType': 'APPLICATION'}}},\n",
       "  'inputs': [],\n",
       "  'outputs': []},\n",
       " {'eventTime': '2025-12-05T04:51:04.919Z',\n",
       "  'producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "  'schemaURL': 'https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent',\n",
       "  'eventType': 'COMPLETE',\n",
       "  'run': {'runId': '019aecd9-6f06-7e59-b7d1-765db69d6f7b',\n",
       "   'facets': {'parent': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/facets/1-1-0/ParentRunFacet.json#/$defs/ParentRunFacet',\n",
       "     'run': {'runId': '019aecd9-65c4-77c5-ab1b-584ff2b7a5dd'},\n",
       "     'job': {'namespace': 'default', 'name': 'py_spark_lineage'},\n",
       "     'root': {'run': {'runId': '019aecd9-65c4-77c5-ab1b-584ff2b7a5dd'},\n",
       "      'job': {'namespace': 'default', 'name': 'PySparkLineage'}}},\n",
       "    'spark_properties': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet',\n",
       "     'properties': {'spark.master': 'local[*]',\n",
       "      'spark.app.name': 'PySparkLineage'}},\n",
       "    'processing_engine': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet',\n",
       "     'version': '3.5.7',\n",
       "     'name': 'spark',\n",
       "     'openlineageAdapterVersion': '1.40.1'},\n",
       "    'environment-properties': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet',\n",
       "     'environment-properties': {}}}},\n",
       "  'job': {'namespace': 'default',\n",
       "   'name': 'py_spark_lineage.collect_limit',\n",
       "   'facets': {'jobType': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "     '_schemaURL': 'https://openlineage.io/spec/facets/2-0-3/JobTypeJobFacet.json#/$defs/JobTypeJobFacet',\n",
       "     'processingType': 'BATCH',\n",
       "     'integration': 'SPARK',\n",
       "     'jobType': 'SQL_JOB'}}},\n",
       "  'inputs': [{'namespace': 'file',\n",
       "    'name': '/C:/Users/GenAICHNSIRUSR22/srinath/output_data.csv',\n",
       "    'facets': {'dataSource': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "      '_schemaURL': 'https://openlineage.io/spec/facets/1-0-1/DatasourceDatasetFacet.json#/$defs/DatasourceDatasetFacet',\n",
       "      'name': 'file',\n",
       "      'uri': 'file'},\n",
       "     'schema': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "      '_schemaURL': 'https://openlineage.io/spec/facets/1-2-0/SchemaDatasetFacet.json#/$defs/SchemaDatasetFacet',\n",
       "      'fields': [{'name': 'value', 'type': 'string'}]}},\n",
       "    'inputFacets': {'inputStatistics': {'_producer': 'https://github.com/OpenLineage/OpenLineage/tree/1.40.1/integration/spark',\n",
       "      '_schemaURL': 'https://openlineage.io/spec/facets/1-0-0/InputStatisticsInputDatasetFacet.json#/$defs/InputStatisticsInputDatasetFacet',\n",
       "      'size': 3342,\n",
       "      'fileCount': 1}}}],\n",
       "  'outputs': []}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# retrieve_and_print_json(MONGODB_URI, DATABASE_NAME, COLLECTION_NAME)\n",
    "retrieve_and_print_json_getlatest(MONGODB_URI, DATABASE_NAME, COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d79908f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def retrieve_latest_completed_job_json(mongo_uri, db_name, collection_name, job_name):\n",
    "#     \"\"\"\n",
    "#     Connects to MongoDB and retrieves the single document for the \n",
    "#     specified job_name where 'eventType' is 'COMPLETE' and has the \n",
    "#     latest 'eventTime'.\n",
    "#     \"\"\"\n",
    "#     client = None # Initialize client outside try block for proper closing\n",
    "#     try:\n",
    "#         # 1. Connect to MongoDB\n",
    "#         client = MongoClient(mongo_uri)\n",
    "#         db = client[db_name]\n",
    "#         collection = db[collection_name]\n",
    "#         print(f\"‚úÖ Successfully connected to MongoDB database '{db_name}'.\")\n",
    "\n",
    "#         # 2. Define the Query and Sort/Limit Conditions\n",
    "        \n",
    "#         # Condition 1 & 2: Filter for specific job name AND eventType 'COMPLETE'\n",
    "#         query_filter = {\n",
    "#             \"job.name\": job_name,\n",
    "#             \"eventType\": \"COMPLETE\"\n",
    "#         }\n",
    "        \n",
    "#         # Condition 3: Sort by 'eventTime' descending (latest first)\n",
    "#         sort_criteria = [(\"eventTime\", -1)] # -1 for descending order\n",
    "        \n",
    "#         # Projection to exclude '_id'\n",
    "#         projection = {'_id': 0}\n",
    "\n",
    "#         # 3. Execute the Query\n",
    "#         # Use limit(1) to only retrieve the very first document (the latest one)\n",
    "#         latest_document_cursor = collection.find(\n",
    "#             query_filter, \n",
    "#             projection\n",
    "#         ).sort(sort_criteria).limit(1)\n",
    "        \n",
    "#         retrieved_document = list(latest_document_cursor)\n",
    "\n",
    "#         if not retrieved_document:\n",
    "#             print(f\"‚ùå No 'COMPLETE' documents found for job: '{job_name}' in collection '{collection_name}'.\")\n",
    "#             return\n",
    "\n",
    "#         # The result is a list with at most one document\n",
    "#         doc = retrieved_document[0]\n",
    "        \n",
    "#         print(f\"‚úÖ Retrieved latest 'COMPLETE' document for job: '{job_name}'. Printing document:\")\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "#         # 4. Print the document as a single-line JSON string\n",
    "#         json_output = json.dumps(doc)\n",
    "#         print(json_output)\n",
    "        \n",
    "#         print(\"-\" * 50)\n",
    "        \n",
    "#         return doc # Optionally return the Python dictionary object\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå An error occurred during the MongoDB retrieval operation: {e}\")\n",
    "#     finally:\n",
    "#         # 5. Close the MongoDB connection\n",
    "#         if client:\n",
    "#             client.close()\n",
    "#             print(\"Connection closed.\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77d3dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Example Usage (Assuming you have your connection details) ---\n",
    "     \n",
    "# # --- Configuration ---\n",
    "# MONGODB_URI = \"mongodb://localhost:27017/\" \n",
    "# DATABASE_NAME = \"Pyspark_OpenLineageDB\"               # Changed for clarity\n",
    "# COLLECTION_NAME = \"lineage_events\"           # Changed for clarity\n",
    "# JSON_FILE_PATH = \"pyspark_lineage.json\"          # Confirmed file name\n",
    "# # --- End Configuration ---\n",
    "\n",
    "# retrieve_latest_completed_job_json(MONGODB_URI, DATABASE_NAME, COLLECTION_NAME, TARGET_JOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cf2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
